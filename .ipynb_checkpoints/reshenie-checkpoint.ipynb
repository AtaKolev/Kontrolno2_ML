{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](zad1.jpg \"Zadacha 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a)\n",
    "image = np.array([[4,5,2,2,1], [3,3,2,2,4], [4,3,4,1,1], [5,1,4,1,2], [5,1,3,1,4]])\n",
    "conv_kernel = np.array([[4,3,3], [5,5,5], [2,4,3]])\n",
    "pading = 0\n",
    "channel = 1\n",
    "stride = 1 # stupka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_output = math.floor(1 + ((image.shape[0] + 2*pading - conv_kernel.shape[0])/stride))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_output = math.floor(1 + ((image.shape[1] + 2*pading - conv_kernel.shape[1])/stride))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Razmerite na izhoda shte sa 3x3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Razmerite na izhoda shte sa {H_output}x{W_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array([[4,5,2], [3,3,2], [4,3,4]]) * conv_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array([[5,2,2], [3,2,2], [3,4,1]]) * conv_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array([[2,2,1], [2,2,4], [4,1,1]]) * conv_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array([[3,3,2], [4,3,4], [5,1,4]]) * conv_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array([[3,2,2], [3,4,1], [1,4,1]]) * conv_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array([[2,2,4], [4,1,1], [4,1,2]]) * conv_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array([[4,3,4], [5,1,4], [5,1,3]]) * conv_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array([[3,4,1], [1,4,1], [1,3,1]]) * conv_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array([[4,1,1], [4,1,2], [3,1,4]]) * conv_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient = np.ones((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Всеки елемент е равен на сбора от елементите на филтъра, с които е участвал в образуването на резултата\n",
    "#### Централният елемент х3,3: dy/dx33 = сумата от целия филтър, тъй като взима участие в образуването на всеки елемент от резултата, с всеки елемент от филтъра"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivate_image = np.array([[4, 7, 10, 6, 3], [9, 17, 25, 16, 8], [11, 23, 34, 23, 11], [7, 16, 24, 17, 8], [2, 6, 9, 7, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  7, 10,  6,  3],\n",
       "       [ 9, 17, 25, 16,  8],\n",
       "       [11, 23, 34, 23, 11],\n",
       "       [ 7, 16, 24, 17,  8],\n",
       "       [ 2,  6,  9,  7,  3]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derivate_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](zad2.jpg \"Zadacha 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_set_dir = r'/home/nasko/Desktop/NBU_MAG/sem2/Machine_Learning_II/kontrolno2/datasets' \n",
    "training_set_dir = r'S:\\Repos\\Kontrolno2_ML\\datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends as cudnn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train' : transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                  transforms.RandomHorizontalFlip(),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "}\n",
    "\n",
    "data_dir = training_set_dir\n",
    "image_datasets = {'train': datasets.ImageFolder(os.path.join(data_dir, 'train'),\n",
    "                    data_transforms['train'])}\n",
    "dataloaders = {'train' : torch.utils.data.DataLoader(image_datasets['train'], batch_size = 4, shuffle = True, num_workers = 4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = {'train' : len(image_datasets['train'])}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls '/home/nasko/Desktop/NBU_MAG/sem2/Machine_Learning_II/kontrolno2/datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_categories = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11356/361484350.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\BRATKO\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36mcurrent_device\u001b[1;34m()\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcurrent_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m     \u001b[1;34mr\"\"\"Returns the index of a currently selected device.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 481\u001b[1;33m     \u001b[0m_lazy_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    482\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\BRATKO\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    208\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\atana/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58e711d92a2442d8cc59647ee120570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/528M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_ft = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = model_ft.classifier[0].out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# otstranqvane na poslednite dva sloq\n",
    "model_ft.classifier = nn.Sequential(*list(model_ft.classifier.children())[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=33, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.classifier.append(nn.Linear(num_features, num_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spirane update na veche treniranite layeri\n",
    "for i in range(len(list(model_ft.features.parameters()))-2):\n",
    "    list(model_ft.features.parameters())[i].requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trenirane na posledniq layer\n",
    "training_layer = list(model_ft.classifier.children())[-1]\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Nastroika na optimizatora\n",
    "optimizer_ft = optim.SGD(training_layer.parameters(), lr = 0.001, momentum = 0.9)\n",
    "\n",
    "# Namalqvane na learning rate, za da ne se podmine globalen minimum\n",
    "lr_scheduled = lr_scheduler.StepLR(optimizer_ft, step_size = 7, gamma = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, dataloaders, num_epochs = 25):\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        print(f\"Epoch: {epoch}/{num_epochs}\")\n",
    "        print('-'*10)\n",
    "\n",
    "        phase = 'train'\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        i = 0\n",
    "        for inputs, labels in dataloaders['train']:\n",
    "            if i % 100 == 0:\n",
    "                print(f\"{i}th Iteration\")\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            i+=1\n",
    "        scheduler.step()\n",
    "        epoch_loss = running_loss / dataset_size['train']\n",
    "        epoch_acc = running_corrects.double() / dataset_size['train']\n",
    "\n",
    "        print(f\"{phase} | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f} |\")\n",
    "\n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5\n",
      "----------\n",
      "0th Iteration\n",
      "100th Iteration\n",
      "200th Iteration\n",
      "300th Iteration\n",
      "400th Iteration\n",
      "500th Iteration\n",
      "600th Iteration\n",
      "700th Iteration\n",
      "800th Iteration\n",
      "900th Iteration\n",
      "1000th Iteration\n",
      "1100th Iteration\n",
      "1200th Iteration\n",
      "1300th Iteration\n",
      "1400th Iteration\n",
      "1500th Iteration\n",
      "1600th Iteration\n",
      "1700th Iteration\n",
      "1800th Iteration\n",
      "1900th Iteration\n",
      "2000th Iteration\n",
      "2100th Iteration\n",
      "2200th Iteration\n",
      "2300th Iteration\n",
      "2400th Iteration\n",
      "2500th Iteration\n",
      "2600th Iteration\n",
      "2700th Iteration\n",
      "2800th Iteration\n",
      "2900th Iteration\n",
      "3000th Iteration\n",
      "3100th Iteration\n",
      "3200th Iteration\n",
      "3300th Iteration\n",
      "3400th Iteration\n",
      "3500th Iteration\n",
      "3600th Iteration\n",
      "3700th Iteration\n",
      "3800th Iteration\n",
      "3900th Iteration\n",
      "4000th Iteration\n",
      "4100th Iteration\n",
      "4200th Iteration\n",
      "train | Loss: 0.3765 | Acc: 0.9066 |\n",
      "\n",
      "Epoch: 2/5\n",
      "----------\n",
      "0th Iteration\n",
      "100th Iteration\n",
      "200th Iteration\n",
      "300th Iteration\n",
      "400th Iteration\n",
      "500th Iteration\n",
      "600th Iteration\n",
      "700th Iteration\n",
      "800th Iteration\n",
      "900th Iteration\n",
      "1000th Iteration\n",
      "1100th Iteration\n",
      "1200th Iteration\n",
      "1300th Iteration\n",
      "1400th Iteration\n",
      "1500th Iteration\n",
      "1600th Iteration\n",
      "1700th Iteration\n",
      "1800th Iteration\n",
      "1900th Iteration\n",
      "2000th Iteration\n",
      "2100th Iteration\n",
      "2200th Iteration\n",
      "2300th Iteration\n",
      "2400th Iteration\n",
      "2500th Iteration\n",
      "2600th Iteration\n",
      "2700th Iteration\n",
      "2800th Iteration\n",
      "2900th Iteration\n",
      "3000th Iteration\n",
      "3100th Iteration\n",
      "3200th Iteration\n",
      "3300th Iteration\n",
      "3400th Iteration\n",
      "3500th Iteration\n",
      "3600th Iteration\n",
      "3700th Iteration\n",
      "3800th Iteration\n",
      "3900th Iteration\n",
      "4000th Iteration\n",
      "4100th Iteration\n",
      "4200th Iteration\n",
      "train | Loss: 0.1799 | Acc: 0.9557 |\n",
      "\n",
      "Epoch: 3/5\n",
      "----------\n",
      "0th Iteration\n",
      "100th Iteration\n",
      "200th Iteration\n",
      "300th Iteration\n",
      "400th Iteration\n",
      "500th Iteration\n",
      "600th Iteration\n",
      "700th Iteration\n",
      "800th Iteration\n",
      "900th Iteration\n",
      "1000th Iteration\n",
      "1100th Iteration\n",
      "1200th Iteration\n",
      "1300th Iteration\n",
      "1400th Iteration\n",
      "1500th Iteration\n",
      "1600th Iteration\n",
      "1700th Iteration\n",
      "1800th Iteration\n",
      "1900th Iteration\n",
      "2000th Iteration\n",
      "2100th Iteration\n",
      "2200th Iteration\n",
      "2300th Iteration\n",
      "2400th Iteration\n",
      "2500th Iteration\n",
      "2600th Iteration\n",
      "2700th Iteration\n",
      "2800th Iteration\n",
      "2900th Iteration\n",
      "3000th Iteration\n",
      "3100th Iteration\n",
      "3200th Iteration\n",
      "3300th Iteration\n",
      "3400th Iteration\n",
      "3500th Iteration\n",
      "3600th Iteration\n",
      "3700th Iteration\n",
      "3800th Iteration\n",
      "3900th Iteration\n",
      "4000th Iteration\n",
      "4100th Iteration\n",
      "4200th Iteration\n",
      "train | Loss: 0.1574 | Acc: 0.9632 |\n",
      "\n",
      "Epoch: 4/5\n",
      "----------\n",
      "0th Iteration\n",
      "100th Iteration\n",
      "200th Iteration\n",
      "300th Iteration\n",
      "400th Iteration\n",
      "500th Iteration\n",
      "600th Iteration\n",
      "700th Iteration\n",
      "800th Iteration\n",
      "900th Iteration\n",
      "1000th Iteration\n",
      "1100th Iteration\n",
      "1200th Iteration\n",
      "1300th Iteration\n",
      "1400th Iteration\n",
      "1500th Iteration\n",
      "1600th Iteration\n",
      "1700th Iteration\n",
      "1800th Iteration\n",
      "1900th Iteration\n",
      "2000th Iteration\n",
      "2100th Iteration\n",
      "2200th Iteration\n",
      "2300th Iteration\n",
      "2400th Iteration\n",
      "2500th Iteration\n",
      "2600th Iteration\n",
      "2700th Iteration\n",
      "2800th Iteration\n",
      "2900th Iteration\n",
      "3000th Iteration\n",
      "3100th Iteration\n",
      "3200th Iteration\n",
      "3300th Iteration\n",
      "3400th Iteration\n",
      "3500th Iteration\n",
      "3600th Iteration\n",
      "3700th Iteration\n",
      "3800th Iteration\n",
      "3900th Iteration\n",
      "4000th Iteration\n",
      "4100th Iteration\n",
      "4200th Iteration\n",
      "train | Loss: 0.1533 | Acc: 0.9661 |\n",
      "\n",
      "Epoch: 5/5\n",
      "----------\n",
      "0th Iteration\n",
      "100th Iteration\n",
      "200th Iteration\n",
      "300th Iteration\n",
      "400th Iteration\n",
      "500th Iteration\n",
      "600th Iteration\n",
      "700th Iteration\n",
      "800th Iteration\n",
      "900th Iteration\n",
      "1000th Iteration\n",
      "1100th Iteration\n",
      "1200th Iteration\n",
      "1300th Iteration\n",
      "1400th Iteration\n",
      "1500th Iteration\n",
      "1600th Iteration\n",
      "1700th Iteration\n",
      "1800th Iteration\n",
      "1900th Iteration\n",
      "2000th Iteration\n",
      "2100th Iteration\n",
      "2200th Iteration\n",
      "2300th Iteration\n",
      "2400th Iteration\n",
      "2500th Iteration\n",
      "2600th Iteration\n",
      "2700th Iteration\n",
      "2800th Iteration\n",
      "2900th Iteration\n",
      "3000th Iteration\n",
      "3100th Iteration\n",
      "3200th Iteration\n",
      "3300th Iteration\n",
      "3400th Iteration\n",
      "3500th Iteration\n",
      "3600th Iteration\n",
      "3700th Iteration\n",
      "3800th Iteration\n",
      "3900th Iteration\n",
      "4000th Iteration\n",
      "4100th Iteration\n",
      "4200th Iteration\n",
      "train | Loss: 0.1160 | Acc: 0.9744 |\n",
      "\n",
      "Training complete in 967m 37s\n",
      "Best val Acc: 0.974427\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, lr_scheduled, dataloaders, num_epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=33, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft, r'S:\\Repos\\Kontrolno2_ML\\model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = torch.load(r'S:\\Repos\\Kontrolno2_ML\\model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=33, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft.classifier, r'S:\\Repos\\Kontrolno2_ML\\model_classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_layer_params = model_ft.classifier[-1].state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.state_dict of Linear(in_features=4096, out_features=33, bias=True)>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_layer_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_layer_params, r'S:\\Repos\\Kontrolno2_ML\\trained_layer_params.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=33, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load.classifier = nn.Sequential(*list(model_ft.classifier.children())[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_layer = torch.load(r'S:\\Repos\\Kontrolno2_ML\\trained_layer_params.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.state_dict of Linear(in_features=4096, out_features=33, bias=True)>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_layer = nn.Linear(num_features, num_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=33, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=33, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load.classifier.append(new_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[ 0.0146,  0.0098,  0.0081,  ...,  0.0091,  0.0085, -0.0002],\n",
       "                      [-0.0003, -0.0124,  0.0138,  ..., -0.0063,  0.0070, -0.0122],\n",
       "                      [-0.0009, -0.0016, -0.0031,  ..., -0.0131, -0.0142, -0.0101],\n",
       "                      ...,\n",
       "                      [-0.0137, -0.0046,  0.0042,  ...,  0.0074, -0.0087, -0.0138],\n",
       "                      [-0.0015,  0.0136, -0.0099,  ...,  0.0011, -0.0096,  0.0128],\n",
       "                      [ 0.0044, -0.0137, -0.0043,  ..., -0.0041, -0.0101,  0.0055]])),\n",
       "             ('bias',\n",
       "              tensor([-7.3045e-03,  4.7504e-03, -2.1292e-04,  1.0856e-02,  5.7537e-06,\n",
       "                       3.2052e-03,  1.4618e-02,  1.3269e-03,  1.5154e-02,  3.6447e-03,\n",
       "                       1.0946e-03,  4.2677e-03, -1.0533e-02,  1.6405e-03, -9.1994e-05,\n",
       "                      -1.1186e-02,  1.3285e-02, -1.1687e-02, -7.3571e-03, -1.9899e-03,\n",
       "                      -1.2146e-02,  3.8632e-03, -2.8399e-03,  1.1175e-02, -9.0390e-03,\n",
       "                       1.3432e-02, -3.7543e-03,  7.7975e-03, -8.2990e-03,  1.0297e-02,\n",
       "                       2.0412e-03, -1.4219e-02, -1.7452e-03]))])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load.classifier[-1].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[-0.0671,  0.0593,  0.0153,  ...,  0.0139,  0.0122,  0.0226],\n",
       "                      [ 0.0091,  0.0865,  0.0038,  ...,  0.0003,  0.0026, -0.0071],\n",
       "                      [ 0.0398,  0.0399, -0.0712,  ...,  0.0078, -0.1073, -0.0272],\n",
       "                      ...,\n",
       "                      [-0.0288, -0.0424, -0.0150,  ...,  0.0063,  0.0994,  0.0036],\n",
       "                      [-0.0419,  0.0965, -0.0134,  ..., -0.0049, -0.0159, -0.0067],\n",
       "                      [-0.0287,  0.0053, -0.0139,  ..., -0.0128, -0.0095,  0.0238]])),\n",
       "             ('bias',\n",
       "              tensor([-0.0173, -0.0234, -0.0152, -0.0008,  0.0103,  0.0177, -0.0107,  0.0079,\n",
       "                       0.0052, -0.0177,  0.0127,  0.0164,  0.0056, -0.0181, -0.0370, -0.0015,\n",
       "                       0.0277, -0.0172,  0.0066, -0.0107,  0.0022, -0.0187, -0.0080,  0.0012,\n",
       "                      -0.0065, -0.0044, -0.0163, -0.0163,  0.0260, -0.0092,  0.0154,  0.0040,\n",
       "                      -0.0038]))])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.classifier[-1].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load.classifier[-1].state_dict = loaded_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[-0.0671,  0.0593,  0.0153,  ...,  0.0139,  0.0122,  0.0226],\n",
       "                      [ 0.0091,  0.0865,  0.0038,  ...,  0.0003,  0.0026, -0.0071],\n",
       "                      [ 0.0398,  0.0399, -0.0712,  ...,  0.0078, -0.1073, -0.0272],\n",
       "                      ...,\n",
       "                      [-0.0288, -0.0424, -0.0150,  ...,  0.0063,  0.0994,  0.0036],\n",
       "                      [-0.0419,  0.0965, -0.0134,  ..., -0.0049, -0.0159, -0.0067],\n",
       "                      [-0.0287,  0.0053, -0.0139,  ..., -0.0128, -0.0095,  0.0238]])),\n",
       "             ('bias',\n",
       "              tensor([-0.0173, -0.0234, -0.0152, -0.0008,  0.0103,  0.0177, -0.0107,  0.0079,\n",
       "                       0.0052, -0.0177,  0.0127,  0.0164,  0.0056, -0.0181, -0.0370, -0.0015,\n",
       "                       0.0277, -0.0172,  0.0066, -0.0107,  0.0022, -0.0187, -0.0080,  0.0012,\n",
       "                      -0.0065, -0.0044, -0.0163, -0.0163,  0.0260, -0.0092,  0.0154,  0.0040,\n",
       "                      -0.0038]))])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load.classifier[-1].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "74adf99108d090a5d5a30d68baa9d82e7a2ef24b286559257e597dbc783a10b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
